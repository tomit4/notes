<?xml version="1.0" encoding="UTF-8"?><feed xmlns="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/"><category term="DataHoarder" label="r/DataHoarder"/><updated>2023-01-28T12:59:23+00:00</updated><icon>https://www.redditstatic.com/icon.png/</icon><id>/r/DataHoarder.rss</id><link rel="self" href="https://www.reddit.com/r/DataHoarder.rss" type="application/atom+xml" /><link rel="alternate" href="https://www.reddit.com/r/DataHoarder" type="text/html" /><subtitle>This is a sub that aims at bringing data hoarders together to share their passion with like minded people.</subtitle><title>It's A Digital Disease!</title><entry><author><name>/u/Seagate_Surfer</name><uri>https://www.reddit.com/user/Seagate_Surfer</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;For this one, we are giving away an IronWolf Pro 125 960GB SSD to one lucky winner in this thread!&lt;/p&gt; &lt;p&gt;Happy New Year! To kick 2023 off right, here&amp;#39;s the terms for this one:&lt;/p&gt; &lt;p&gt;&lt;strong&gt;The prize is: one IronWolf Pro 125 960GB SSD&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;How to enter:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Just reply to this post once with a comment that includes the terms RunWithIronWolf and Seagate telling us how the prize would help further your data hoarding projects.&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;Selection process/rules&lt;/p&gt; &lt;p&gt;One entry per person. Using alt accounts will result in a ban. New accounts created after this post went live are not eligible. Entries are open until January 31st 2023, 23:59 UTC. We will use a random raffler utility to filter out top level comments (that is, top-level replies to this post, not to another comment, and not on any cross-posts). The tool will remove duplicate usernames, sort the list, and grab the randomly chosen username, at which point the winner will be contacted within a day or so of the giveaway ending. Winners will have 48 hrs to get us their physical address and contact details for shipping (no PO boxes). Any person who does not reply in time loses their spot and everyone moves up a tier. For example: the 1st place person does not respond, so the 2nd place person gets contacted. Seagate will use the information strictly for shipping purposes only and will ship the drive directly. We reserve the right to edit this post including this process and these rules without notice. This is reddit, after all.&lt;/p&gt; &lt;p&gt;Geographic restrictions:&lt;/p&gt; &lt;p&gt;Our policy is for our forums and Reddit giveaways to be global where local shipping and/or giveaway restrictions/current world events don’t prevent us, however we are basing the below list of eligible counties from previous giveaways, as some counties have unique restrictions (e.g. the obvious shipping restrictions to Russia and Belarus currently)&lt;/p&gt; &lt;p&gt;US&lt;/p&gt; &lt;p&gt;Canada (exc. Quebec and will require a basic skills-based question if winner is chosen by law)&lt;/p&gt; &lt;p&gt;Brazil&lt;/p&gt; &lt;p&gt;South America&lt;/p&gt; &lt;p&gt;United Kingdom&lt;/p&gt; &lt;p&gt;Germany&lt;/p&gt; &lt;p&gt;France&lt;/p&gt; &lt;p&gt;Iberia&lt;/p&gt; &lt;p&gt;Australia&lt;/p&gt; &lt;p&gt;New Zealand&lt;/p&gt; &lt;p&gt;Korea&lt;/p&gt; &lt;p&gt;India&lt;/p&gt; &lt;p&gt;Malaysia&lt;/p&gt; &lt;p&gt;Singapore&lt;/p&gt; &lt;p&gt;China&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Seagate_Surfer&quot;&gt; /u/Seagate_Surfer &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10jjdfe/were_back_official_january_2023_seagate_ironwolf/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10jjdfe/were_back_official_january_2023_seagate_ironwolf/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10jjdfe</id><link href="https://www.reddit.com/r/DataHoarder/comments/10jjdfe/were_back_official_january_2023_seagate_ironwolf/" /><updated>2023-01-23T18:20:07+00:00</updated><published>2023-01-23T18:20:07+00:00</published><title>We're Back - Official January 2023 Seagate IronWolf Giveaway!</title></entry><entry><author><name>/u/AutoModerator</name><uri>https://www.reddit.com/user/AutoModerator</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Talk about general topics in our Discussion Thread!&lt;/p&gt; &lt;ul&gt; &lt;li&gt;Try out new software that you liked/hated? &lt;/li&gt; &lt;li&gt;Tell us about that $40 2TB MicroSD card from Amazon that&amp;#39;s totally not a scam&lt;/li&gt; &lt;li&gt;Come show us how much data you lost since you didn&amp;#39;t have backups!&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Totally not an attempt to build community rapport.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AutoModerator&quot;&gt; /u/AutoModerator &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mwnmn/datahoarder_discussion/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mwnmn/datahoarder_discussion/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mwnmn</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mwnmn/datahoarder_discussion/" /><updated>2023-01-27T21:30:10+00:00</updated><published>2023-01-27T21:30:10+00:00</published><title>DataHoarder Discussion</title></entry><entry><author><name>/u/jabberwockxeno</name><uri>https://www.reddit.com/user/jabberwockxeno</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://twitter.com/HaloCEmaps/status/1614854187300552705&quot;&gt;https://twitter.com/HaloCEmaps/status/1614854187300552705&lt;/a&gt;&lt;/p&gt; &lt;p&gt;The Halomaps forums have tons of information on Halo Custom edition and Halo 2V modding, as well as tons of images and videos of mods and custom content that wasn&amp;#39;t ever publicly released outside of those previews. It&amp;#39;d be an enormous blow if all of it was lost.&lt;/p&gt; &lt;p&gt;I don&amp;#39;t know enough about archiving websites to help out here (I&amp;#39;d love to learn, but not in the short timespan this requires), so I&amp;#39;m hoping people here can figure something out, I&amp;#39;m also gonna make a post on &lt;a href=&quot;/r/Halo&quot;&gt;/r/Halo&lt;/a&gt; and will update the post here with a link when I do.&lt;/p&gt; &lt;p&gt;I know @haloman30 on twitter is doing some archiving, but I don&amp;#39;t know how complete it would be, so reaching out to them might be fruitful too.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jabberwockxeno&quot;&gt; /u/jabberwockxeno &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mswav/halomaps_which_has_been_the_main_hub_for_halo/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mswav/halomaps_which_has_been_the_main_hub_for_halo/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mswav</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mswav/halomaps_which_has_been_the_main_hub_for_halo/" /><updated>2023-01-27T19:00:32+00:00</updated><published>2023-01-27T19:00:32+00:00</published><title>Halomaps, which has been the main hub for Halo modding content for almost 20 years, is having it's forums shut down on Feb 1st. A massive amount of content will be lost if it's not archived.</title></entry><entry><author><name>/u/m8wt</name><uri>https://www.reddit.com/user/m8wt</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/m8wt&quot;&gt; /u/m8wt &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://blog.archive.org/2023/01/27/bbc-modi-documentary-removal/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n7b7t/bbc_modi_documentary_removal_internet_archive/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10n7b7t</id><link href="https://www.reddit.com/r/DataHoarder/comments/10n7b7t/bbc_modi_documentary_removal_internet_archive/" /><updated>2023-01-28T05:34:22+00:00</updated><published>2023-01-28T05:34:22+00:00</published><title>BBC Modi Documentary Removal - Internet Archive Blogs</title></entry><entry><author><name>/u/DepressMyCNS</name><uri>https://www.reddit.com/user/DepressMyCNS</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;So recently YouTube made some more changes to their rules and they seem to be retroactively applying them and striking channels. As of now this is mostly an issue with the 2A/Firearms communities of YouTube but I&amp;#39;m sure this will be affecting all channels breaking any of the new rules and old one, this is just another wave content crackdown.&lt;/p&gt; &lt;p&gt;I&amp;#39;m not sure how many of you saw, but &lt;a href=&quot;https://twitter.com/GarandThumb1/status/1618748298550190083?t=HIExkVleJ258UaSlsNLWOw&amp;amp;s=19&quot;&gt;Garand Thumb got a content strike&lt;/a&gt; thanks to YouTube new policies on an old video, this means they are retroactively applying this and all of the firearms channels on YouTube are in danger of disappearing soon if they strike 3 videos, content creators will also be having to go through their backlog and remove videos that might be in violation of these new rules. &lt;/p&gt; &lt;p&gt;I honestly think the ultimate goal in this new &amp;quot;no showing assembly or disassembly of a firearm&amp;quot; rule is to limit the information on the internet about caring for and maintaining firearms. If they ever do manage to destroy our 2A rights and attempt a gun grab, the weapons that manage to be stashed away will need to be well kept up and that why they&amp;#39;re removing the info now, to damage the chances of future generations. Even if it is for a less ominous reason, we&amp;#39;re still in danger of losing hours of entertainment and memories from our favorite creators.&lt;/p&gt; &lt;p&gt;Our best way to fight this is kick into archival mode. We need to start downloading every video we care about especially anything involving the essentials like firearms basics, training, shooting tips, cleaning, maintainance, safety etc. I&amp;#39;m doing what I can to backup all the videos as well as their descriptions and the comments section so any useful information is saved, but I feel like I&amp;#39;m kinda overwhelmed and ill prepared for a backup task like this. I&amp;#39;m going to see what I can do about storage and how many channels I can back up. Now&amp;#39;s where you guys come in!&lt;/p&gt; &lt;p&gt;&lt;strong&gt;If you want to help archive channels, here&amp;#39;s the easiest way&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I looked around for hours and the information on how to archive channels is very difficult to understand and near impossible to setup however I finally found a workaround and that&amp;#39;s what I&amp;#39;m here to share with you! The most efficient and effective program I&amp;#39;ve found is &lt;a href=&quot;https://tartube.sourceforge.io/&quot;&gt;TarTube&lt;/a&gt; this application is an installer and GUI for the very popular yt-dlp and ffmpeg combo to download batch videos from YouTube. The only problem I found with those programs is because they run through command line it was basically impossible for me to get it to work, however TarTube takes care of all the setup and gets rid of the need for knowing command line prompts and replaces it with a relatively slick GUI. I&amp;#39;m going to break down the steps as quickly and easily as I can for anyome interested in helping preserve this Era of YouTube that may be coming to a close. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; &lt;a href=&quot;https://tartube.sourceforge.io/#downloads&quot;&gt;Download the TarTube installer for your specific OS&lt;/a&gt;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Follow the on screen instructions for installing yt-dlp ffmpeg and the TarTube GUI program, it&amp;#39;s relatively simple, you might need to run as admin depending on your settings.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; (possibly optional) Give your PC a reboot to make sure the new files are installed in the system and will run properly. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Open Tar Tube and click on the &amp;quot;Classic Mode&amp;quot; tab that&amp;#39;s 3 tabs in on the 3rd menu column &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 5.&lt;/strong&gt; Select &amp;quot;Edit&amp;quot; from the main menu in the top left corner of the screen, then select &amp;quot;General Download Preferences&amp;quot;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 6.&lt;/strong&gt; Select the &amp;quot;Post Processing&amp;quot; tab then select &amp;quot;Audio quality of the post processed file&amp;quot; Change it from &amp;quot;Medium VBR&amp;quot; to 320kbps or 256kbps, 1080p YouTube videos have their audio tracks limited to 256kbps but by selecting 320kbps you&amp;#39;re insuring that the rip maintains the highest possible quality even though your not upconverting it or anything. Select &amp;quot;Okay&amp;quot; and you should be back in the &amp;quot;Classic Mode&amp;quot; tab. Nows where we get rolling. &lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 7.&lt;/strong&gt; Grab the URL of the video or playlist you want to download from the web and paste it into the &amp;quot;Enter URLs Below Box&amp;quot;&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 8.&lt;/strong&gt; Select the destination you want the videos to download to on your storage. Then click the &amp;quot;Add URLs&amp;quot; button to the right.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Step 9.&lt;/strong&gt; Select &amp;quot;Download All&amp;quot; in the bottom right corner and let the program work its magic.&lt;/p&gt; &lt;p&gt;So far I&amp;#39;ve ripped 3 playlist and am working on a whole channel now, the time has varied between 5 to 30 minutes but I&amp;#39;m on a decent speed connection. This is definitely a community job so if you have the storage and the free time help preserve the content we have today for future generations.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DepressMyCNS&quot;&gt; /u/DepressMyCNS &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n0t7i/easily_archive_youtube_channels_and_videos/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n0t7i/easily_archive_youtube_channels_and_videos/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10n0t7i</id><link href="https://www.reddit.com/r/DataHoarder/comments/10n0t7i/easily_archive_youtube_channels_and_videos/" /><updated>2023-01-28T00:19:47+00:00</updated><published>2023-01-28T00:19:47+00:00</published><title>Easily Archive YouTube Channels and Videos - Classic YouTube videos in Danger after new rule changes. We need to start archiving our favorite content.</title></entry><entry><author><name>/u/jasonbaker125</name><uri>https://www.reddit.com/user/jasonbaker125</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;a href=&quot;https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026&quot;&gt;https://hothardware.com/news/seagate-says-30tb-drives-coming-soon-and-50tb-by-2026&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/jasonbaker125&quot;&gt; /u/jasonbaker125 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mycpv/do_you_think_seagates_hdds_will_get_to_50_tb_by/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mycpv/do_you_think_seagates_hdds_will_get_to_50_tb_by/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mycpv</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mycpv/do_you_think_seagates_hdds_will_get_to_50_tb_by/" /><updated>2023-01-27T22:38:48+00:00</updated><published>2023-01-27T22:38:48+00:00</published><title>Do you think Seagate's HDD's will get to 50 TB by 2026 and 100 TB by 2030? Seagate thinks so.</title></entry><entry><author><name>/u/n0llbyte</name><uri>https://www.reddit.com/user/n0llbyte</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Created a script to use when moving large amounts of data between folders/servers and wanting to skip `Force Recheck` inside the torrent client.&lt;br/&gt; You just point it to your rTorrent `session` folder, specify the path to change and the new path and it&amp;#39;ll replace all session data.&lt;br/&gt; For example, when moving torrents from `/downloads/Temp` to `/downloads/Movies` you can use this script like so:&lt;/p&gt; &lt;pre&gt;&lt;code&gt;python torrent-mover.py --src /downloads/Temp/ --dst /downloads/Movies/ /config/rTorrent/session &lt;/code&gt;&lt;/pre&gt; &lt;p&gt;Currently, it supports rTorrent only!&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://github.com/uraid/torrent-mover&quot;&gt;https://github.com/uraid/torrent-mover&lt;/a&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/n0llbyte&quot;&gt; /u/n0llbyte &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10ne0q5/change_the_path_for_downloaded_torrents_without/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10ne0q5/change_the_path_for_downloaded_torrents_without/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ne0q5</id><link href="https://www.reddit.com/r/DataHoarder/comments/10ne0q5/change_the_path_for_downloaded_torrents_without/" /><updated>2023-01-28T12:32:13+00:00</updated><published>2023-01-28T12:32:13+00:00</published><title>Change the path for downloaded torrents without force recheck</title></entry><entry><author><name>/u/HopeThisIsUnique</name><uri>https://www.reddit.com/user/HopeThisIsUnique</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mazgf/colorado_landscape_photographer_john_fielder/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=87482844e5b37608776fdafc6bba318530a2c07c&quot; alt=&quot;Colorado landscape photographer John Fielder donates entire life's work to public domain&quot; title=&quot;Colorado landscape photographer John Fielder donates entire life's work to public domain&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Keep your eyes open over the coming months, this will be incredibly beautiful artwork to add to any collection.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/HopeThisIsUnique&quot;&gt; /u/HopeThisIsUnique &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://petapixel.com/2023/01/26/celebrated-nature-photographer-donates-lifes-work-to-public-domain/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mazgf/colorado_landscape_photographer_john_fielder/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_10mazgf</id><media:thumbnail url="https://external-preview.redd.it/f0BTkWzMB3QDB5qxvBdIp4tPR0_DpagU7Aw2JpDZmmQ.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=87482844e5b37608776fdafc6bba318530a2c07c" /><link href="https://www.reddit.com/r/DataHoarder/comments/10mazgf/colorado_landscape_photographer_john_fielder/" /><updated>2023-01-27T03:32:07+00:00</updated><published>2023-01-27T03:32:07+00:00</published><title>Colorado landscape photographer John Fielder donates entire life's work to public domain</title></entry><entry><author><name>/u/rackhamlerouge9</name><uri>https://www.reddit.com/user/rackhamlerouge9</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;m sure many have observed that High-capacity Blu-ray still represents a cost effective medium, if only someone would make a 2 meter stack of them and &amp;#39;tap&amp;#39; the hole/lumen down the middle so that a threaded pole could be &amp;#39;screwed&amp;#39; in from each end to a set point, to retract the undesired discs away from the desired disc, and allow it to be removed for data retrieval. Or a carousel; I&amp;#39;m not fussy.&lt;/p&gt; &lt;p&gt;Anyway if I understand correctly, back in 2013, &lt;a href=&quot;https://en.wikipedia.org/wiki/Ernst_Abbe&quot;&gt;Abbe&lt;/a&gt;&amp;#39;s limit was circumvented (lay article &lt;a href=&quot;https://theconversation.com/more-data-storage-heres-how-to-fit-1-000-terabytes-on-a-dvd-15306&quot;&gt;here&lt;/a&gt;, and the paper in Nature Communications &lt;a href=&quot;https://www.nature.com/articles/ncomms3061&quot;&gt;here&lt;/a&gt;), and the 500nm &amp;#39;smallest defect&amp;#39; became 9nm. There was now only the matter of finding a physical medium that could reliably hold such fine etchings.&lt;/p&gt; &lt;p&gt;Well, I&amp;#39;m here to moan about it. I&amp;#39;ve been waiting aaaaages. Where&amp;#39;re my petabyte DVDs?? I figure if anyone knows the answer, they probably check in with this hive mind occasionally...&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/rackhamlerouge9&quot;&gt; /u/rackhamlerouge9 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10negvg/where_are_my_1000tb_dvds/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10negvg/where_are_my_1000tb_dvds/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10negvg</id><link href="https://www.reddit.com/r/DataHoarder/comments/10negvg/where_are_my_1000tb_dvds/" /><updated>2023-01-28T12:57:43+00:00</updated><published>2023-01-28T12:57:43+00:00</published><title>Where are my 1000TB DVDs?</title></entry><entry><author><name>/u/candroid_man</name><uri>https://www.reddit.com/user/candroid_man</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mx37y/found_2_of_these_in_an_old_nas_machine_if_they/&quot;&gt; &lt;img src=&quot;https://preview.redd.it/97ekw77fpnea1.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=c59fb09b6e802c453c97360d0c6842b5b50748db&quot; alt=&quot;Found 2 of these in an old NAS machine, if they work would these be good to use for my server?&quot; title=&quot;Found 2 of these in an old NAS machine, if they work would these be good to use for my server?&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/candroid_man&quot;&gt; /u/candroid_man &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://i.redd.it/97ekw77fpnea1.jpg&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mx37y/found_2_of_these_in_an_old_nas_machine_if_they/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_10mx37y</id><media:thumbnail url="https://preview.redd.it/97ekw77fpnea1.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=c59fb09b6e802c453c97360d0c6842b5b50748db" /><link href="https://www.reddit.com/r/DataHoarder/comments/10mx37y/found_2_of_these_in_an_old_nas_machine_if_they/" /><updated>2023-01-27T21:47:36+00:00</updated><published>2023-01-27T21:47:36+00:00</published><title>Found 2 of these in an old NAS machine, if they work would these be good to use for my server?</title></entry><entry><author><name>/u/PessimisticHoarder</name><uri>https://www.reddit.com/user/PessimisticHoarder</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I ran DoD short on 5x 8tb disks prior to selling them. They had been running in my server for around 25-35k hours without errors, SMART OK. Now I get feedback from my first customer saying it’s not working at all. Not recognized/errors. Did DoD short kill them?&lt;/p&gt; &lt;p&gt;I did not run any tests after DoD. But it finished without errors.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/PessimisticHoarder&quot;&gt; /u/PessimisticHoarder &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10ndn27/how_common_is_it_for_dban_to_destroy_an_hdd/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10ndn27/how_common_is_it_for_dban_to_destroy_an_hdd/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ndn27</id><link href="https://www.reddit.com/r/DataHoarder/comments/10ndn27/how_common_is_it_for_dban_to_destroy_an_hdd/" /><updated>2023-01-28T12:10:07+00:00</updated><published>2023-01-28T12:10:07+00:00</published><title>How common is it for DBAN to destroy an HDD?</title></entry><entry><author><name>/u/kanczug</name><uri>https://www.reddit.com/user/kanczug</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Did someone manage to get a hold of Blindy.tv streams library before it got shut down few years ago? I just learned how great content it hosted - turning tv shows like Star Trek to audio episodes with additional commentary for the blind, which make it great for in car listening.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/kanczug&quot;&gt; /u/kanczug &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10ncg5h/blindytv_anyone/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10ncg5h/blindytv_anyone/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10ncg5h</id><link href="https://www.reddit.com/r/DataHoarder/comments/10ncg5h/blindytv_anyone/" /><updated>2023-01-28T10:54:37+00:00</updated><published>2023-01-28T10:54:37+00:00</published><title>Blindy.tv anyone?</title></entry><entry><author><name>/u/prion</name><uri>https://www.reddit.com/user/prion</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I have asked a few times in &lt;a href=&quot;/r/software&quot;&gt;r/software&lt;/a&gt; and I&amp;#39;ve looked on the internet but I still can&amp;#39;t find exactly what I am looking for.&lt;/p&gt; &lt;p&gt;What am I looking for you may ask?&lt;/p&gt; &lt;p&gt;I&amp;#39;m looking for a database solution that can store full html pages, allows you to organize them by topic and tab, and has a full text search for all your locally stored websites. I&amp;#39;d also like it to have an import feature that allows you to import already downloaded webpages. Ublock origin combined with Singlefile makes a heck of a poorman&amp;#39;s instapaper display of content, I just need a database to save all these pages in.&lt;/p&gt; &lt;p&gt;What I&amp;#39;ve tried so far:&lt;/p&gt; &lt;p&gt;Onenote: I love onenote. I&amp;#39;ve used it for 16 years now. Its just not what I am looking for for this solution. Even with a cleaned page it takes far too long to import and tagging is not really what I want either.&lt;/p&gt; &lt;p&gt;Eagle: This is an awesome app. It does everything I want for a storage solution except it does not have full text search. Developer does not seem responsive when I have reached out to him asking for this feature to be added. To be fair this app was designed as a image and object solution and not a HTML storage solution so there is that. Its not really intended for my usecase but its the closest I have seen so far.&lt;/p&gt; &lt;p&gt;Notion: No, just no. Gets too slow when it gets huge and it does not load the entire page with the web clipper.&lt;/p&gt; &lt;p&gt;Pocket: I cannot find a solution that allows local storage outside their apps and for free&lt;/p&gt; &lt;p&gt;Instapaper: I cannot find a solution that will accept my username and password, all Windows Apps seem broken.&lt;/p&gt; &lt;p&gt;I&amp;#39;m not interested in downloading entire websites, merely collecting items and sorting them into categories of knowledge I want to build.&lt;/p&gt; &lt;p&gt;&amp;#x200B;&lt;/p&gt; &lt;p&gt;Any ideas?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/prion&quot;&gt; /u/prion &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10na03y/looking_for_a_webpage_storage_solution/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10na03y/looking_for_a_webpage_storage_solution/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10na03y</id><link href="https://www.reddit.com/r/DataHoarder/comments/10na03y/looking_for_a_webpage_storage_solution/" /><updated>2023-01-28T08:17:00+00:00</updated><published>2023-01-28T08:17:00+00:00</published><title>Looking for a webpage storage solution</title></entry><entry><author><name>/u/vadhavaniyafaijan</name><uri>https://www.reddit.com/user/vadhavaniyafaijan</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;table&gt; &lt;tr&gt;&lt;td&gt; &lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mqrb8/popular_pirate_website_scihub_se_is_banned_now/&quot;&gt; &lt;img src=&quot;https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=640&amp;amp;crop=smart&amp;amp;auto=webp&amp;amp;s=8e9207697ba31479a48693f8bf256bf89a25e8a2&quot; alt=&quot;Popular Pirate Website Sci-Hub .Se Is Banned Now&quot; title=&quot;Popular Pirate Website Sci-Hub .Se Is Banned Now&quot; /&gt; &lt;/a&gt; &lt;/td&gt;&lt;td&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/vadhavaniyafaijan&quot;&gt; /u/vadhavaniyafaijan &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.theinsaneapp.com/2023/01/scihub-banned.html&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mqrb8/popular_pirate_website_scihub_se_is_banned_now/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt; &lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;</content><id>t3_10mqrb8</id><media:thumbnail url="https://external-preview.redd.it/LTOqQwDi7Wrlr2ZlJ1-LjpftYimW91rvO7Suv4g9M-M.jpg?width=640&amp;crop=smart&amp;auto=webp&amp;s=8e9207697ba31479a48693f8bf256bf89a25e8a2" /><link href="https://www.reddit.com/r/DataHoarder/comments/10mqrb8/popular_pirate_website_scihub_se_is_banned_now/" /><updated>2023-01-27T17:36:17+00:00</updated><published>2023-01-27T17:36:17+00:00</published><title>Popular Pirate Website Sci-Hub .Se Is Banned Now</title></entry><entry><author><name>/u/descavenger</name><uri>https://www.reddit.com/user/descavenger</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve recently been given a 3.5&amp;quot; 4TB HDD for free that I&amp;#39;d like to use as additional storage for my PC (Plex Server) however my desktop tower can only fit one HDD which I&amp;#39;ve already got a 4TB HDD in. What is the most affordable way to permanently have this HDD connected to by PC externally whilst remaining safe? I read docking stations can cause heating issues and are only good for temporary HDD swaps. So would an enclosure be sufficient (does plastic vs aluminium matter)? Any affordable recommendations, please?&lt;/p&gt; &lt;p&gt;Alternatively, should I just get a USB to SATA converter and use this HDD as a backup (which I&amp;#39;ll then store somewhere else) and purchase a proper external HD? (this would be more costly so ideally don&amp;#39;t want to do this).&lt;/p&gt; &lt;p&gt;Edit: In response to some of the comments - I can&amp;#39;t change the desktop case, the dell optiplex&amp;#39;s have a lot of propriety parts that make it very difficult to change. It&amp;#39;s also not my goal here, trying to keep this as simple as possible.&lt;/p&gt; &lt;p&gt;Update: Going with an aluminium enclosure.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/descavenger&quot;&gt; /u/descavenger &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10m7hwu/best_way_to_use_a_spare_external_hdd_as_storage/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10m7hwu/best_way_to_use_a_spare_external_hdd_as_storage/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10m7hwu</id><link href="https://www.reddit.com/r/DataHoarder/comments/10m7hwu/best_way_to_use_a_spare_external_hdd_as_storage/" /><updated>2023-01-27T00:40:36+00:00</updated><published>2023-01-27T00:40:36+00:00</published><title>Best way to use a spare external HDD as storage?</title></entry><entry><author><name>/u/Theoneandonlyjustin</name><uri>https://www.reddit.com/user/Theoneandonlyjustin</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;DVD recorder - Magnavox MSR90D2. Every Time I hit the record button it just records static. I&amp;#39;ve tried video in via VHS player and ive tried video in via a coax antenna and no matter what all I get is static when i I hit record . I don&amp;#39;t have the remote so I go to menu&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Theoneandonlyjustin&quot;&gt; /u/Theoneandonlyjustin &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n2sle/whats_going_wrong_vhs_to_dvd/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n2sle/whats_going_wrong_vhs_to_dvd/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10n2sle</id><link href="https://www.reddit.com/r/DataHoarder/comments/10n2sle/whats_going_wrong_vhs_to_dvd/" /><updated>2023-01-28T01:47:30+00:00</updated><published>2023-01-28T01:47:30+00:00</published><title>whats going wrong VHS to dvd</title></entry><entry><author><name>/u/LazarusLong67</name><uri>https://www.reddit.com/user/LazarusLong67</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Any thoughts on this drive? It&amp;#39;s currently steeply discounted at Best Buy and Amazon for $240. Was thinking of picking one up just for some extra storage (in addition to my 20TB of HDD).&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/LazarusLong67&quot;&gt; /u/LazarusLong67 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n2ngy/crucial_x8_4tb_external_ssd/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n2ngy/crucial_x8_4tb_external_ssd/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10n2ngy</id><link href="https://www.reddit.com/r/DataHoarder/comments/10n2ngy/crucial_x8_4tb_external_ssd/" /><updated>2023-01-28T01:40:53+00:00</updated><published>2023-01-28T01:40:53+00:00</published><title>Crucial X8 4TB external SSD</title></entry><entry><author><name>/u/Beautiful-Ad-9304</name><uri>https://www.reddit.com/user/Beautiful-Ad-9304</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi, I have a problem. My HDD somehow disconnected itself while defragmentation and now it shows up as RAW, is there any way to convert it to NTFS without losing data and folder structure? It’s very important because there is 15yrs of my life on this disk.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Beautiful-Ad-9304&quot;&gt; /u/Beautiful-Ad-9304 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n1ii2/data_recovery/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n1ii2/data_recovery/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10n1ii2</id><link href="https://www.reddit.com/r/DataHoarder/comments/10n1ii2/data_recovery/" /><updated>2023-01-28T00:50:25+00:00</updated><published>2023-01-28T00:50:25+00:00</published><title>Data recovery</title></entry><entry><author><name>/u/AnonymousAardvark22</name><uri>https://www.reddit.com/user/AnonymousAardvark22</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I would like to be able to keep libvirt qcow2 virtual machine images synced via a cloud provider, encrypted, and synced incrementally so that if I will not have re-upload an entire 30/40GB virtual image just because I logged into a VM and made a very small change.&lt;/p&gt; &lt;p&gt;A koofr dev has stated they had to choose zero knowledge encryption which apparently cannot work with incremental sync. If I were roling my own encryption with rclone perhaps there is a workaround. I read about restic but it seems to be for backup rather than sync.&lt;/p&gt; &lt;p&gt;I have been using Cryptomator with Insync on GDrive for general cloud use but I would like to try rclone on a new provider and I am considering filen and koofr at the moment.&lt;/p&gt; &lt;p&gt;Is client-side encrypted incremental sync possible, and if so can it work with those two providers or should I consider another?&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/AnonymousAardvark22&quot;&gt; /u/AnonymousAardvark22 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mz8go/incrementalblocklevel_clientside_encrypted_sync/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mz8go/incrementalblocklevel_clientside_encrypted_sync/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mz8go</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mz8go/incrementalblocklevel_clientside_encrypted_sync/" /><updated>2023-01-27T23:15:16+00:00</updated><published>2023-01-27T23:15:16+00:00</published><title>Incremental/block-level client-side encrypted sync of large files?</title></entry><entry><author><name>/u/DarkCesare</name><uri>https://www.reddit.com/user/DarkCesare</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve got probably all of the album preview pic links in a text file, 19580 lines/links. Made the sequence via C language. but my pc isn&amp;#39;t powerful enough to download/process all the links via IDM. Would anyone please download the files in a single folder and zip share it to me as well or in the community?&lt;/p&gt; &lt;p&gt;here is the txt file:&lt;/p&gt; &lt;p&gt;&lt;a href=&quot;https://mega.nz/file/nhdRlK5Y#zsXBU3fxp-0GIHfBMG-FUSuF1PXY3Cr4yQdO6-SGCyQ&quot;&gt;https://mega.nz/file/nhdRlK5Y#zsXBU3fxp-0GIHfBMG-FUSuF1PXY3Cr4yQdO6-SGCyQ&lt;/a&gt;&lt;/p&gt; &lt;p&gt;Edit: there&amp;#39;s already an archive &amp;quot;r18.dev&amp;quot;&lt;/p&gt; &lt;p&gt;&amp;amp; mine seems to be incomplete! but still can be kinda used 🐸 to batch download other series by replacing the word 1dvdes with 1hunta, h_094ktds &amp;amp; such. Thanks Everyone!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DarkCesare&quot;&gt; /u/DarkCesare &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mcl3k/dear_datahoarders_as_you_might_know_r18_is/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mcl3k/dear_datahoarders_as_you_might_know_r18_is/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mcl3k</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mcl3k/dear_datahoarders_as_you_might_know_r18_is/" /><updated>2023-01-27T04:56:56+00:00</updated><published>2023-01-27T04:56:56+00:00</published><title>Dear DataHoarders, As you might know, r18 is shutting down permanently on 31st January. But I've got links to the pictures to save as memory. Would anyone help?</title></entry><entry><author><name>/u/DrWho345</name><uri>https://www.reddit.com/user/DrWho345</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Could anyone kindly suggest a mac program that is able to either sync two folders together or best identify what files are missing between two folders.&lt;/p&gt; &lt;p&gt;Example&lt;/p&gt; &lt;p&gt;I have been trying to get an exact copy of a folder I currently have, which has all of my photos in it, and just do a plain, straightforward backup. I have used a lot of programs in the past but for some reason there is a discrepancy\difference of 3 files between the two folders and for the life of me I can&amp;#39;t figure out what they are, and can&amp;#39;t get them to sync. &lt;/p&gt; &lt;p&gt;Carbon Copy Cloner can&amp;#39;t find them, even SyncTime can&amp;#39;t find them. I have even tried Compare Folders but it takes way to long to populate.&lt;/p&gt; &lt;p&gt;Any suggestions would be very helpful&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DrWho345&quot;&gt; /u/DrWho345 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10myt2p/best_organisingsyncing_program_for_mac_to_keep/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10myt2p/best_organisingsyncing_program_for_mac_to_keep/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10myt2p</id><link href="https://www.reddit.com/r/DataHoarder/comments/10myt2p/best_organisingsyncing_program_for_mac_to_keep/" /><updated>2023-01-27T22:57:55+00:00</updated><published>2023-01-27T22:57:55+00:00</published><title>Best organising\syncing program for Mac to keep files the same</title></entry><entry><author><name>/u/EargasmicGiant</name><uri>https://www.reddit.com/user/EargasmicGiant</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;&lt;strong&gt;&lt;em&gt;does anyone know what i can install on a buffalo nas? i want a media server like Emby to install but buffalo linkstations are never listed&lt;/em&gt;&lt;/strong&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/EargasmicGiant&quot;&gt; /u/EargasmicGiant &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10myesc/buffalo_linkstation/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10myesc/buffalo_linkstation/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10myesc</id><link href="https://www.reddit.com/r/DataHoarder/comments/10myesc/buffalo_linkstation/" /><updated>2023-01-27T22:41:09+00:00</updated><published>2023-01-27T22:41:09+00:00</published><title>buffalo linkstation</title></entry><entry><author><name>/u/Jbales8990</name><uri>https://www.reddit.com/user/Jbales8990</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hi all, apologies if this ends up being simple but this is slightly outside my normal IT wheelhouse. I am currently in the process of upgrading my company&amp;#39;s public computer lab from HDD&amp;#39;s to SSD&amp;#39;s and soon I will have roughly ~25 1Tb HDD&amp;#39;s that will not be in use anymore. My idea is to create a file server since we don&amp;#39;t currently have one and it could be very useful to us. It doesn&amp;#39;t have to be anything particularly fancy we just want to be able to share and access files from within the building. So my question is, what is the easiest way to go about doing so? I haven&amp;#39;t messed around with RAID configurations since college and that&amp;#39;s been well over a decade ago so I&amp;#39;m a little rusty. I&amp;#39;ve seen a few articles about ZFS but I wanted to get some actual opinions as opposed to just doing the first thing a website says. The other issue is, how do I store and power that many drives? Any help is appreciated.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Jbales8990&quot;&gt; /u/Jbales8990 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mxk8a/creating_network_file_storage/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mxk8a/creating_network_file_storage/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mxk8a</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mxk8a/creating_network_file_storage/" /><updated>2023-01-27T22:06:37+00:00</updated><published>2023-01-27T22:06:37+00:00</published><title>Creating Network File Storage</title></entry><entry><author><name>/u/Throwaway23145656</name><uri>https://www.reddit.com/user/Throwaway23145656</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Is there any site that has an archive of old twitch steams/vods? I&amp;#39;ve had a look at the wayback machine and the internet archive, but they don&amp;#39;t seem complete and don&amp;#39;t work that well.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/Throwaway23145656&quot;&gt; /u/Throwaway23145656 &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n2pi9/any_way_to_download_old_twitch_streamsvods/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10n2pi9/any_way_to_download_old_twitch_streamsvods/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10n2pi9</id><link href="https://www.reddit.com/r/DataHoarder/comments/10n2pi9/any_way_to_download_old_twitch_streamsvods/" /><updated>2023-01-28T01:43:33+00:00</updated><published>2023-01-28T01:43:33+00:00</published><title>Any way to download old twitch streams/vods?</title></entry><entry><author><name>/u/DepressMyCNS</name><uri>https://www.reddit.com/user/DepressMyCNS</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hey all I&amp;#39;m working on a data archiving project and a guide for layman&amp;#39;s as YouTube is cracking down once again and we need as many people archiving as possible. &lt;/p&gt; &lt;p&gt;The program I&amp;#39;m using is called TarTube, it&amp;#39;s a GUI and installer based off of yt-dlp and ffmpeg, I was successfully able to bulk download an entire playlist easily, so it&amp;#39;s great for capturing videos but I&amp;#39;ve been digging through the setting and was unable to find a way to easily capture the descriptions and comments for each video.&lt;/p&gt; &lt;p&gt;If anyone can help me figure out how to configure this it will be much appreciated!&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/DepressMyCNS&quot;&gt; /u/DepressMyCNS &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mx890/need_help_capturing_youtube_descriptions_and/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mx890/need_help_capturing_youtube_descriptions_and/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mx890</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mx890/need_help_capturing_youtube_descriptions_and/" /><updated>2023-01-27T21:53:18+00:00</updated><published>2023-01-27T21:53:18+00:00</published><title>Need help capturing YouTube descriptions and comments.</title></entry><entry><author><name>/u/peter-baumann</name><uri>https://www.reddit.com/user/peter-baumann</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;I&amp;#39;ve been lurking on here for a while and watched lots of YouTube reviews/tutorials/guides, but still not quite certain of the best direction to take. I&amp;#39;m hoping to get some advice on best options for a NAS for my use case.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Context:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I work in audio &amp;amp; video and the majority of my active projects run off 4x Crucial SSDs housed in a Blackmagic Multidock 10G. Here&amp;#39;s a summary of my SSD setup for active projects.&lt;/p&gt; &lt;ul&gt; &lt;li&gt;2TB MacBook Pro Internal SSD&lt;/li&gt; &lt;li&gt;7TB across 4x Crucial MX500 SSDs — only one of the 2TB is regularly being written to.&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;Once completed, archived projects are migrated to various HDDs:&lt;/p&gt; &lt;ul&gt; &lt;li&gt;6TB WD Elements (mirrored via Arq backup to a 6TB Seagate Backup Plus) — 2.7TB currently free&lt;/li&gt; &lt;li&gt;3TB Seagate Expansion&lt;/li&gt; &lt;li&gt;1TB Toshiba (cold storage of images)&lt;/li&gt; &lt;/ul&gt; &lt;p&gt;A 12TB WD Elements then backs up as much of the SSD content (active) and archives as possible via Arq, but that&amp;#39;s now full.&lt;/p&gt; &lt;p&gt;I&amp;#39;ve got a (very cheap initial) year of 10TB iDrive for backing up priority files off-site, but this level of storage quickly becomes extremely expensive for offsite cloud-based backups.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Possible Solutions:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;I was eyeing up a 20TB WD Elements for £290 but that&amp;#39;s no longer available and I was on the fence about it as it won&amp;#39;t slim down the total number of drives, or provide me with redundant storage if I use it exclusively. Having gone from 6 to 12TB in a few years, I&amp;#39;m also not confident that 20TB is going to be a long-term solution.&lt;/p&gt; &lt;p&gt;I then started looking at Synology units, but there are a so many options and they&amp;#39;re not cheap. Not really sure where to start...!&lt;/p&gt; &lt;p&gt;Although I&amp;#39;m techie, I&amp;#39;ve never built my own PC. Following instructions I&amp;#39;m good at, though, so I don&amp;#39;t think it&amp;#39;s completely out of the question to do a DIY build! 😆 I&amp;#39;ve seen &lt;a href=&quot;https://www.youtube.com/watch?v=boKmZKTKXHc&quot;&gt;LTT&amp;#39;s Jonsbo N1 build&lt;/a&gt;, but sourcing that case is tricky. It comes to a similar price as some of the Synology units, but I quite like the idea of being able to do upgrades further down the line, but in terms of hardware and software.&lt;/p&gt; &lt;p&gt;I&amp;#39;m not too worried about appearance. It&amp;#39;s almost definitely going to end up out of sight.&lt;/p&gt; &lt;p&gt;&lt;strong&gt;Some preferred outcomes:&lt;/strong&gt;&lt;/p&gt; &lt;p&gt;☑️ As low energy usage as possible (although not to the point of diminishing returns vs energy bills).&lt;br/&gt; ☑️ Suitable for (1) redundant data backup of archive projects not housed on active SSDs and (2) hourly/daily backups of active projects that are housed on SSDs (using Arq backup?).&lt;br/&gt; ☑️ Possibility of duplicating/having a similar system off-site to cut out 3rd party cloud storage subscriptions but still have an off-site backup.&lt;br/&gt; ☑️ Expandable&lt;br/&gt; ☑️ I have gigabit hardwired network (not wifi, just local)&lt;br/&gt; ☑️ Ideally a free management solution (TrueNAS)&lt;br/&gt; ❌ I am not looking to edit off the NAS currently (I&amp;#39;m not sure there&amp;#39;s a particular need, with the Crucial SSDs in the Multidock giving me plenty of quick storage). I also don&amp;#39;t need to work with collaborators or other editors from shared storage via the NAS.&lt;br/&gt; 🤔 A quiet unit would be great, although it&amp;#39;s not likely to be sat on my desk next to me so this is not essential.&lt;br/&gt; 🤔 I don&amp;#39;t currently plan on using it for media storage, but it&amp;#39;s not out of the question that a portion of the storage might be allocated to media storage in the future (assuming that&amp;#39;s possible with the above considered).&lt;/p&gt; &lt;p&gt;What would you suggest?&lt;/p&gt; &lt;p&gt;&lt;em&gt;Also posted to /HomeServer&lt;/em&gt;&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/peter-baumann&quot;&gt; /u/peter-baumann &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mx73h/advice_needed_prebuilt_or_diy_nas/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mx73h/advice_needed_prebuilt_or_diy_nas/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mx73h</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mx73h/advice_needed_prebuilt_or_diy_nas/" /><updated>2023-01-27T21:51:59+00:00</updated><published>2023-01-27T21:51:59+00:00</published><title>Advice needed: Prebuilt or DIY NAS</title></entry><entry><author><name>/u/arscorvinus</name><uri>https://www.reddit.com/user/arscorvinus</uri></author><category term="DataHoarder" label="r/DataHoarder"/><content type="html">&lt;!-- SC_OFF --&gt;&lt;div class=&quot;md&quot;&gt;&lt;p&gt;Hello everyone!&lt;br/&gt; I am creating a loooong term archive using DVDs and Blu Rays.&lt;/p&gt; &lt;p&gt;(I use my external drives and NAS for my current stuff but some of it has to be archived elsewhere and I got tired of replacing crashing hard drives every year or two)&lt;/p&gt; &lt;p&gt;So, the question is:&lt;br/&gt; What is the best way to store them to make them last longer?&lt;/p&gt; &lt;p&gt;Are plastic sleeves ok? Or should I get the rigid thin boxes? Could I simply burn them and put them back in the &amp;quot;tower&amp;quot; boxes? (spindle?) etc.&lt;/p&gt; &lt;p&gt;NOTE: Once they are in the correct case, they will go to an Archival Cabinet (fireproof and waterproof) with oxygen and humidity absorbers along with some other Archival stuff I have there.&lt;/p&gt; &lt;/div&gt;&lt;!-- SC_ON --&gt; &amp;#32; submitted by &amp;#32; &lt;a href=&quot;https://www.reddit.com/user/arscorvinus&quot;&gt; /u/arscorvinus &lt;/a&gt; &lt;br/&gt; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mwrud/best_ways_to_store_discs/&quot;&gt;[link]&lt;/a&gt;&lt;/span&gt; &amp;#32; &lt;span&gt;&lt;a href=&quot;https://www.reddit.com/r/DataHoarder/comments/10mwrud/best_ways_to_store_discs/&quot;&gt;[comments]&lt;/a&gt;&lt;/span&gt;</content><id>t3_10mwrud</id><link href="https://www.reddit.com/r/DataHoarder/comments/10mwrud/best_ways_to_store_discs/" /><updated>2023-01-27T21:34:50+00:00</updated><published>2023-01-27T21:34:50+00:00</published><title>Best ways to store DISCS?</title></entry></feed>